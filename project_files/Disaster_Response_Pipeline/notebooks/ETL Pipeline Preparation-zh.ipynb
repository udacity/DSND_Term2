{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ETL Pipeline \n",
    "按照下面的说明，创建你的 ETL 管道。\n",
    "### 1. 导入与加载.\n",
    "- 导入 Python 库\n",
    "- 将 `messages.csv` 导入数据框，查看前几行\n",
    "- 将 `categories.csv` 导入数据框，查看前几行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load messages dataset\n",
    "messages = \n",
    "messages.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load categories dataset\n",
    "categories = \n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 合并数据集\n",
    "- 使用相同的 id 合并 messages 和 categories 数据集\n",
    "- 将合并后的数据集传入 `df`，在后续的步骤中要清洗该数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge datasets\n",
    "df = \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 分割 `categories` \n",
    "- 将 `categories` 列的值根据字符 `;` 进行分割，每个值是一个新列。你会发现 [这个方法](https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.Series.str.split.html) 非常有用。确保设置 `expand=True`。\n",
    "- 使用 categories 数据框的第一行来创建类别数据的列名。\n",
    "- 使用新的列名重命名 `categories` 的列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of the 36 individual category columns\n",
    "categories = \n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the first row of the categories dataframe\n",
    "row = \n",
    "\n",
    "# use this row to extract a list of new column names for categories.\n",
    "# one way is to apply a lambda function that takes everything \n",
    "# up to the second to last character of each string with slicing\n",
    "category_colnames = \n",
    "print(category_colnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns of `categories`\n",
    "categories.columns = category_colnames\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 转换类别值至数值 0 或 1\n",
    "- 遍历 df 的类别列，只保留每个字符串的最后一个字符（1 或 0）。例如，`related-0` 变成 `0`，`related-1` 变成 `1`。将字符串转换成数值。\n",
    "- 通过在 Series 后加上`.str`，你可以实现 [Pandas Series 上的常见字符串操作](https://pandas.pydata.org/pandas-docs/stable/text.html#indexing-with-str)，如索引。你可能需要先将 Series 转换成类型字符串，你可以通过 `astype(str)` 实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in categories:\n",
    "    # set each value to be the last character of the string\n",
    "    categories[column] = \n",
    "    \n",
    "    # convert column from string to numeric\n",
    "    categories[column] = \n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 替换 `df` `categories` 类别列\n",
    "- 从 df 数据框中删除类别列，因为不再需要类别列了。\n",
    "- 将 df 和 categories 数据框连接起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the original categories column from `df`\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the original dataframe with the new `categories` dataframe\n",
    "df = \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 删除重复行\n",
    "- 检查这个数据集中有多少重复行。\n",
    "- 删除重复行。\n",
    "- 确认重复行被删除了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of duplicates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 保存整理后的数据集为 sqlite databse \n",
    "你可以使用 pandas 的 [`to_sql` 方法](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_sql.html) 和SQLAlchemy 库实现这一点。记得在 notebook 的第一个单元格导入 SQLAlchemy 的 `create_engine` 以在下方使用该库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('sqlite:///InsertDatabaseName.db')\n",
    "df.to_sql('InsertTableName', engine, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 在这个notebook 里完成 `etl_pipeline.py`\n",
    "使用 Resources 文件夹中给出的模板文件编写脚本，运行上面的步骤，根据用户指定的新数据库创建一个数据库。或者，你也可以在项目工作环境 IDE 中完成教室中的 `etl_pipeline.py` 。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
