{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Data\n",
    "\n",
    "In this exercise, you'll practice scaling data. Sometimes, you'll see the terms **standardization** and **normalization** used interchangeably when referring to feature scaling. However, these are slightly different operations. Standardization refers to scaling a set of values so that they have a mean of zero and a standard deviation of one. Normalization refers to scaling a set of values so that the range if between zero and one.\n",
    "\n",
    "In this exercise, you'll practice implementing standardization and normalization in code. There are libraries, like scikit-learn, that can do this for you; however, in data engineering, you might not always have these tools available.\n",
    "\n",
    "Run this first cell to read in the World Bank GDP and population data. This code cell also filters the data for 2016 and filters out the aggregated values like 'World' and 'OECD Members'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "# read in the projects data set and do basic wrangling \n",
    "gdp = pd.read_csv('../data/gdp_data.csv', skiprows=4)\n",
    "gdp.drop(['Unnamed: 62', 'Country Code', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1)\n",
    "population = pd.read_csv('../data/population_data.csv', skiprows=4)\n",
    "population.drop(['Unnamed: 62', 'Country Code', 'Indicator Name', 'Indicator Code'], inplace=True, axis=1)\n",
    "\n",
    "\n",
    "# Reshape the data sets so that they are in long format\n",
    "gdp_melt = gdp.melt(id_vars=['Country Name'], \n",
    "                    var_name='year', \n",
    "                    value_name='gdp')\n",
    "\n",
    "# Use back fill and forward fill to fill in missing gdp values\n",
    "gdp_melt['gdp'] = gdp_melt.sort_values('year').groupby('Country Name')['gdp'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "population_melt = population.melt(id_vars=['Country Name'], \n",
    "                                  var_name='year', \n",
    "                                  value_name='population')\n",
    "\n",
    "# Use back fill and forward fill to fill in missing population values\n",
    "population_melt['population'] = population_melt.sort_values('year').groupby('Country Name')['population'].fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# merge the population and gdp data together into one data frame\n",
    "df_country = gdp_melt.merge(population_melt, on=('Country Name', 'year'))\n",
    "\n",
    "# filter data for the year 2016\n",
    "df_2016 = df_country[df_country['year'] == '2016']\n",
    "\n",
    "# filter out values that are not countries\n",
    "non_countries = ['World',\n",
    " 'High income',\n",
    " 'OECD members',\n",
    " 'Post-demographic dividend',\n",
    " 'IDA & IBRD total',\n",
    " 'Low & middle income',\n",
    " 'Middle income',\n",
    " 'IBRD only',\n",
    " 'East Asia & Pacific',\n",
    " 'Europe & Central Asia',\n",
    " 'North America',\n",
    " 'Upper middle income',\n",
    " 'Late-demographic dividend',\n",
    " 'European Union',\n",
    " 'East Asia & Pacific (excluding high income)',\n",
    " 'East Asia & Pacific (IDA & IBRD countries)',\n",
    " 'Euro area',\n",
    " 'Early-demographic dividend',\n",
    " 'Lower middle income',\n",
    " 'Latin America & Caribbean',\n",
    " 'Latin America & the Caribbean (IDA & IBRD countries)',\n",
    " 'Latin America & Caribbean (excluding high income)',\n",
    " 'Europe & Central Asia (IDA & IBRD countries)',\n",
    " 'Middle East & North Africa',\n",
    " 'Europe & Central Asia (excluding high income)',\n",
    " 'South Asia (IDA & IBRD)',\n",
    " 'South Asia',\n",
    " 'Arab World',\n",
    " 'IDA total',\n",
    " 'Sub-Saharan Africa',\n",
    " 'Sub-Saharan Africa (IDA & IBRD countries)',\n",
    " 'Sub-Saharan Africa (excluding high income)',\n",
    " 'Middle East & North Africa (excluding high income)',\n",
    " 'Middle East & North Africa (IDA & IBRD countries)',\n",
    " 'Central Europe and the Baltics',\n",
    " 'Pre-demographic dividend',\n",
    " 'IDA only',\n",
    " 'Least developed countries: UN classification',\n",
    " 'IDA blend',\n",
    " 'Fragile and conflict affected situations',\n",
    " 'Heavily indebted poor countries (HIPC)',\n",
    " 'Low income',\n",
    " 'Small states',\n",
    " 'Other small states',\n",
    " 'Not classified',\n",
    " 'Caribbean small states',\n",
    " 'Pacific island small states']\n",
    "\n",
    "# remove non countries from the data\n",
    "df_2016 = df_2016[~df_2016['Country Name'].isin(non_countries)]\n",
    "\n",
    "\n",
    "# show the first ten rows\n",
    "print('first ten rows of data')\n",
    "df_2016.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise - Normalize the Data\n",
    "\n",
    "To normalize data, you take a feature, like gdp, and use the following formula\n",
    "\n",
    "$x_{normalized} = \\frac{x - x_{min}}{x_{max} - x_{min}}$\n",
    "\n",
    "where \n",
    "* x is a value of gdp\n",
    "* x_max is the maximum gdp in the data\n",
    "* x_min is the minimum GDP in the data\n",
    "\n",
    "First, write a function that outputs the x_min and x_max values of an array. The inputs are an array of data (like the GDP data). The outputs are the x_min and x_max values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_min_max(data):\n",
    "    # TODO: Complete this function called x_min_max() \n",
    "    # The input is an array of data as an input \n",
    "    # The outputs are the minimum and maximum of that array\n",
    "    minimum = None\n",
    "    maximum = None\n",
    "    return minimum, maximum\n",
    "\n",
    "# this should give the result (36572611.88531479, 18624475000000.0)\n",
    "x_min_max(df_2016['gdp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, write a function that normalizes a data point. The inputs are an x value, a minimum value, and a maximum value. The output is the normalized data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, x_min, x_max):\n",
    "    # TODO: Complete this function\n",
    "    # The input is a single value \n",
    "    # The output is the normalized value\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why are you making these separate functions? Let's say you are training a machine learning model and using normalized GDP as a feature. As new data comes in, you'll want to make predictions using the new GDP data. You'll have to normalize this incoming data. To do that, you need to store the x_min and x_max from the training set. Hence the x_min_max() function gives you the minimum and maximum values, which you can then store in a variable.\n",
    "\n",
    "A good way to keep track of the minimum and maximum values would be to use a class. In this next section, fill out the Normalizer() class code to make a class that normalizes a data set and stores min and max values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer():\n",
    "    # TODO: Complete the normalizer class\n",
    "    # The normalizer class receives a dataframe as its only input for initialization\n",
    "    # For example, the data frame might contain gdp and population data in two separate columns\n",
    "    # Follow the TODOs in each section\n",
    "    \n",
    "    def __init__(self, dataframe):\n",
    "        \n",
    "        # TODO: complete the init function. \n",
    "        # Assume the dataframe has an unknown number of columns like [['gdp', 'population']] \n",
    "        # iterate through each column calculating the min and max for each column\n",
    "        # append the results to the params attribute list\n",
    "        \n",
    "        # For example, take the gdp column and calculate the minimum and maximum\n",
    "        # Put these results in a list [minimum, maximum]\n",
    "        # Append the list to the params variable\n",
    "        # Then take the population column and do the same\n",
    "        \n",
    "        # HINT: You can put your x_min_max() function as part of this class and use it\n",
    "        \n",
    "        # HINT: Use a for loop to iterate through the columns of the dataframe\n",
    "        \n",
    "        self.params = []\n",
    "            \n",
    "    def x_min_max(data):\n",
    "        # TODO: complete the x_min_max method\n",
    "        # HINT: You can use the same function defined earlier in the exercise\n",
    "        minimum = None\n",
    "        maximum = None\n",
    "        return minimum, maximum\n",
    "\n",
    "    def normalize_data(self, x):\n",
    "        # TODO: complete the normalize_data method\n",
    "        # The function receives a data point as an input and then outputs the normalized version\n",
    "        # For example, if an input data point of [gdp, population] were used. Then the output would\n",
    "        # be the normalized version of the [gdp, population] data point\n",
    "        # Put the results in the normalized variable defined below\n",
    "        \n",
    "        # Assume that the columns in the dataframe used to initialize an object are in the same\n",
    "        # order as this data point x\n",
    "        \n",
    "        # HINT: You cannot use the normalize_data function defined earlier in the exercise.\n",
    "        # You'll need to iterate through the individual values in the x variable. A for loop and the \n",
    "        #    Python enumerate method might be useful.\n",
    "        # Use the params attribute where the min and max values are stored \n",
    "        normalized = []\n",
    "        return normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cells below to check your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_normalizer = Normalizer(df_2016[['gdp', 'population']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should output: [(36572611.88531479, 18624475000000.0), (11097.0, 1378665000.0)]\n",
    "gdp_normalizer.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should output [0.7207969507229194, 0.9429407193285986]\n",
    "gdp_normalizer.normalize_data([13424475000000.0, 1300000000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "When normalizing or standardizing features for machine learning, you'll need to store the parameters you used to do the scaling. That way you can scale new data points when making predictions. In this exercise, you stored the minimum and maximum values of a feature. When standardizing data, you would need to store the mean and standard deviation. The standardization formula is:\n",
    "\n",
    "$x_{standardized} = \\frac{x - \\overline{x}}{S}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
