{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Content Based Recommendations\n",
    "\n",
    "In the previous notebook, you were introduced to a way to make recommendations using collaborative filtering.  However, using this technique there are a large number of users who were left without any recommendations at all.  Other users were left with fewer than the ten recommendations that were set up by our function to retrieve...\n",
    "\n",
    "In order to help these users out, let's try another technique **content based** recommendations.  Let's start off where we were in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from IPython.display import HTML\n",
    "import progressbar\n",
    "import tests as t\n",
    "import pickle\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Read in the datasets\n",
    "movies = pd.read_csv('movies_clean.csv')\n",
    "reviews = pd.read_csv('reviews_clean.csv')\n",
    "\n",
    "del movies['Unnamed: 0']\n",
    "del reviews['Unnamed: 0']\n",
    "\n",
    "\n",
    "all_recs = pickle.load(open(\"all_recs.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets\n",
    "\n",
    "From the above, you now have access to three important items that you will be using throughout the rest of this notebook.  \n",
    "\n",
    "`a.` **movies** - a dataframe of all of the movies in the dataset along with other content related information about the movies (genre and date)\n",
    "\n",
    "\n",
    "`b.` **reviews** - this was the main dataframe used before for collaborative filtering, as it contains all of the interactions between users and movies.\n",
    "\n",
    "\n",
    "`c.` **all_recs** - a dictionary where each key is a user, and the value is a list of movie recommendations based on collaborative filtering\n",
    "\n",
    "For the individuals in **all_recs** who did recieve 10 recommendations using collaborative filtering, we don't really need to worry about them.  However, there were a number of individuals in our dataset who did not receive any recommendations.\n",
    "\n",
    "-----\n",
    "\n",
    "`1.` To begin, let's start with finding all of the users in our dataset who didn't get all 10 ratings we would have liked them to have using collaborative filtering.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 22187 users with all reccomendations from collaborative filtering.\n",
      "There are 31781 users who still need recommendations.\n",
      "This means that only 41.11% of users received all 10 of their recommendations using collaborative filtering\n"
     ]
    }
   ],
   "source": [
    "users_with_all_recs = []\n",
    "for user, movie_recs in all_recs.items():\n",
    "    if len(movie_recs) > 9:\n",
    "        users_with_all_recs.append(user)\n",
    "\n",
    "print(\"There are {} users with all reccomendations from collaborative filtering.\".format(len(users_with_all_recs)))\n",
    "\n",
    "users = np.unique(reviews['user_id'])\n",
    "users_who_need_recs = np.setdiff1d(users, users_with_all_recs)\n",
    "\n",
    "print(\"There are {} users who still need recommendations.\".format(len(users_who_need_recs)))\n",
    "print(\"This means that only {}% of users received all 10 of their recommendations using collaborative filtering\".format(round(len(users_with_all_recs)/len(np.unique(reviews['user_id'])), 4)*100))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That's right there were still another 31781 users who needed recommendations when we only used collaborative filtering!\n"
     ]
    }
   ],
   "source": [
    "# Some test here might be nice\n",
    "assert len(users_with_all_recs) == 22187\n",
    "print(\"That's right there were still another 31781 users who needed recommendations when we only used collaborative filtering!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content Based Recommendations\n",
    "\n",
    "You will be doing a bit of a mix of content and collaborative filtering to make recommendations for the users this time.  This will allow you to obtain recommendations in many cases where we didn't make recommendations earlier.     \n",
    "\n",
    "`2.` Before finding recommendations, rank the user's ratings from highest ratings to lowest ratings. You will move through the movies in this order looking for other similar movies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a dataframe similar to reviews, but ranked by rating for each user\n",
    "ranked_reviews = reviews.sort_values(by=['user_id', 'rating'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarities\n",
    "\n",
    "In the collaborative filtering sections, you became quite familiar with different methods of determining the similarity (or distance) of two users.  We can perform similarities based on content in much the same way.  \n",
    "\n",
    "In many cases, it turns out that one of the fastest ways we can find out how similar items are to one another (when our matrix isn't totally sparse like it was in the earlier section) is by simply using matrix multiplication.  If you are not familiar with this, an explanation is available [here by 3blue1brown](https://www.youtube.com/watch?v=LyGKycYT2v0) and another quick explanation is provided [on the post here](https://math.stackexchange.com/questions/689022/how-does-the-dot-product-determine-similarity).\n",
    "\n",
    "For us to pull out a matrix that describes the movies in our dataframe in terms of content, we might just use the indicator variables related to **year** and **genre** for our movies.  \n",
    "\n",
    "Then we can obtain a matrix of how similar movies are to one another by taking the dot product of this matrix with itself.  Notice in the below that the dot product where our 1 values overlap gives a value of 2 indicating higher similarity.  In the second dot product, the 1 values don't match up.  This leads to a dot product of 0 indicating lower similarity.\n",
    "\n",
    "<img src=\"images/dotprod1.png\" alt=\"Dot Product\" height=\"500\" width=\"500\">\n",
    "\n",
    "We can perform the dot product on a matrix of movies with content characteristics to provide a movie by movie matrix where each cell is an indication of how similar two movies are to one another.  In the below image, you can see that movies 1 and 8 are most similar, movies 2 and 8 are most similar and movies 3 and 9 are most similar for this subset of the data.  The diagonal elements of the matrix will contain the similarity of a movie with itself, which will be the largest possible similarity (which will also be the number of 1's in the movie row within the orginal movie content matrix.\n",
    "\n",
    "<img src=\"images/moviemat.png\" alt=\"Dot Product\" height=\"500\" width=\"500\">\n",
    "\n",
    "\n",
    "`3.` Create a numpy array that is a matrix of indicator variables related to year (by century) and movie genres by movie.  Perform the dot prodoct of this matrix with itself (transposed) to obtain a similarity matrix of each movie with every other movie.  The final matrix should be 31245 x 31245."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset so movie_content is only using the dummy variables for each genre and the 3 century based year dummy columns\n",
    "movie_content = np.array(movies.iloc[:,4:])\n",
    "\n",
    "# Take the dot product to obtain a movie x movie matrix of similarities\n",
    "dot_prod_movies = movie_content.dot(np.transpose(movie_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looks like you passed all of the tests.  Though they weren't very robust - if you want to write some of your own, I won't complain!\n"
     ]
    }
   ],
   "source": [
    "# create checks for the dot product matrix\n",
    "assert dot_prod_movies.shape[0] == 31245\n",
    "assert dot_prod_movies.shape[1] == 31245\n",
    "assert dot_prod_movies[0, 0] == np.max(dot_prod_movies[0])\n",
    "print(\"Looks like you passed all of the tests.  Though they weren't very robust - if you want to write some of your own, I won't complain!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Each User...\n",
    "\n",
    "\n",
    "Now that you have a matrix where each user has their ratings ordered.  You also have a second matrix where movies are each axis, and the matrix entries are larger where the two movies are more similar and smaller where the two movies are dissimilar.  This matrix is a measure of content similarity. Therefore, it is time to get to the fun part.\n",
    "\n",
    "For each user, we will perform the following:\n",
    "\n",
    "    i. For each movie, find the movies that are most similar that the user hasn't seen.\n",
    "\n",
    "    ii. Continue through the available, rated movies until 10 recommendations or until there are no additional movies.\n",
    "\n",
    "As a final note, you may need to adjust the criteria for 'most similar' to obtain 10 recommendations.  As a first pass, I used only movies with the highest possible similarity to one another as similar enough to add as a recommendation.\n",
    "\n",
    "`3.` In the below cell, complete each of the functions needed for making content based recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_similar_movies(movie_id):\n",
    "    '''\n",
    "    INPUT\n",
    "    movie_id - a movie_id \n",
    "    OUTPUT\n",
    "    similar_movies - an array of the most similar movies by title\n",
    "    '''\n",
    "    # find the row of each movie id\n",
    "    movie_idx = np.where(movies['movie_id'] == movie_id)[0][0]\n",
    "    \n",
    "    # find the most similar movie indices - to start I said they need to be the same for all content\n",
    "    similar_idxs = np.where(dot_prod_movies[movie_idx] == np.max(dot_prod_movies[movie_idx]))[0]\n",
    "    \n",
    "    # pull the movie titles based on the indices\n",
    "    similar_movies = np.array(movies.iloc[similar_idxs, ]['movie'])\n",
    "    \n",
    "    return similar_movies\n",
    "    \n",
    "    \n",
    "def get_movie_names(movie_ids):\n",
    "    '''\n",
    "    INPUT\n",
    "    movie_ids - a list of movie_ids\n",
    "    OUTPUT\n",
    "    movies - a list of movie names associated with the movie_ids\n",
    "    \n",
    "    '''\n",
    "    movie_lst = list(movies[movies['movie_id'].isin(movie_ids)]['movie'])\n",
    "   \n",
    "    return movie_lst\n",
    "\n",
    "def make_recs():\n",
    "    '''\n",
    "    INPUT\n",
    "    None\n",
    "    OUTPUT\n",
    "    recs - a dictionary with keys of the user and values of the recommendations\n",
    "    '''\n",
    "    # Create dictionary to return with users and ratings\n",
    "    recs = defaultdict(set)\n",
    "    # How many users for progress bar\n",
    "    n_users = len(users)\n",
    "\n",
    "    \n",
    "    # Create the progressbar\n",
    "    cnter = 0\n",
    "    bar = progressbar.ProgressBar(maxval=n_users+1, widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
    "    bar.start()\n",
    "    \n",
    "    # For each user\n",
    "    for user in users:\n",
    "        \n",
    "        # Update the progress bar\n",
    "        cnter+=1 \n",
    "        bar.update(cnter)\n",
    "\n",
    "        # Pull only the reviews the user has seen\n",
    "        reviews_temp = ranked_reviews[ranked_reviews['user_id'] == user]\n",
    "        movies_temp = np.array(reviews_temp['movie_id'])\n",
    "        movie_names = np.array(get_movie_names(movies_temp))\n",
    "\n",
    "        # Look at each of the movies (highest ranked first), \n",
    "        # pull the movies the user hasn't seen that are most similar\n",
    "        # These will be the recommendations - continue until 10 recs \n",
    "        # or you have depleted the movie list for the user\n",
    "        for movie in movies_temp:\n",
    "            rec_movies = find_similar_movies(movie)\n",
    "            temp_recs = np.setdiff1d(rec_movies, movie_names)\n",
    "            recs[user].update(temp_recs)\n",
    "\n",
    "            # If there are more than \n",
    "            if len(recs[user]) > 9:\n",
    "                break\n",
    "\n",
    "    bar.finish()\n",
    "    \n",
    "    return recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================================================] 100%\n"
     ]
    }
   ],
   "source": [
    "recs = make_recs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Did We Do?\n",
    "\n",
    "Now that you have made the recommendations, how did we do in providing everyone with a set of recommendations?\n",
    "\n",
    "`4.` Use the cells below to see how many individuals you were able to make recommendations for, as well as explore characteristics about individuals who you were not able to make recommendations for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore recommendations\n",
    "users_without_all_recs = []\n",
    "users_with_all_recs = []\n",
    "no_recs = []\n",
    "for user, movie_recs in recs.items():\n",
    "    if len(movie_recs) < 10:\n",
    "        users_without_all_recs.append(user)\n",
    "    if len(movie_recs) > 9:\n",
    "        users_with_all_recs.append(user)\n",
    "    if len(movie_recs) == 0:\n",
    "        no_recs.append(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 2179 users without all 10 recommendations we would have liked to have.\n",
      "There were 51789 users with all 10 recommendations we would like them to have.\n",
      "There were 174 users with no recommendations at all!\n"
     ]
    }
   ],
   "source": [
    "# Some characteristics of my content based recommendations\n",
    "print(\"There were {} users without all 10 recommendations we would have liked to have.\".format(len(users_without_all_recs)))\n",
    "print(\"There were {} users with all 10 recommendations we would like them to have.\".format(len(users_with_all_recs)))\n",
    "print(\"There were {} users with no recommendations at all!\".format(len(no_recs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([457430])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Closer look at individual user characteristics\n",
    "user_items = reviews[['user_id', 'movie_id', 'rating']]\n",
    "user_by_movie = user_items.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "\n",
    "def movies_watched(user_id):\n",
    "    '''\n",
    "    INPUT:\n",
    "    user_id - the user_id of an individual as int\n",
    "    OUTPUT:\n",
    "    movies - an array of movies the user has watched\n",
    "    '''\n",
    "    movies = user_by_movie.loc[user_id][user_by_movie.loc[user_id].isnull() == False].index.values\n",
    "\n",
    "    return movies\n",
    "\n",
    "\n",
    "movies_watched(189)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the movie lists for users without any recommendations include:\n",
      "189\n",
      "['El laberinto del fauno (2006)']\n",
      "797\n",
      "['The 414s (2015)']\n",
      "1603\n",
      "['Beauty and the Beast (2017)']\n",
      "2056\n",
      "['Brimstone (2016)']\n",
      "2438\n",
      "['Baby Driver (2017)']\n",
      "3322\n",
      "['Rosenberg (2013)']\n",
      "3925\n",
      "['El laberinto del fauno (2006)']\n",
      "4325\n",
      "['Beauty and the Beast (2017)']\n",
      "4773\n",
      "['The Frozen Ground (2013)']\n",
      "4869\n",
      "['Beauty and the Beast (2017)']\n",
      "4878\n",
      "['American Made (2017)']\n"
     ]
    }
   ],
   "source": [
    "cnter = 0\n",
    "print(\"Some of the movie lists for users without any recommendations include:\")\n",
    "for user_id in no_recs:\n",
    "    print(user_id)\n",
    "    print(get_movie_names(movies_watched(user_id)))\n",
    "    cnter+=1\n",
    "    if cnter > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now What?  \n",
    "\n",
    "Well, if you were really strict with your criteria for how similar two movies (like I was initially), then you still have some users that don't have all 10 recommendations (and a small group of users who have no recommendations at all). \n",
    "\n",
    "As stated earlier, recommendation engines are a bit of an **art** and a **science**.  There are a number of things we still could look into - how do our collaborative filtering and content based recommendations compare to one another? How could we incorporate user input along with collaborative filtering and/or content based recommendations to improve any of our recommendations?  How can we truly gain recommendations for every user?\n",
    "\n",
    "`5.` In this last step feel free to explore any last ideas you have with the recommendation techniques we have looked at so far.  You might choose to make the final needed recommendations using the first technique with just top ranked movies.  You might also loosen up the strictness in the similarity needed between movies.  Be creative and share your insights with your classmates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cells for exploring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
